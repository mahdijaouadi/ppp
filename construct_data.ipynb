{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1cf3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import datetime as dt\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "# from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667431f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chart(stock):\n",
    "    fig = go.Figure()\n",
    "    # Add candlestick data\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=stock['Datetime'],\n",
    "        open=stock['Open'],\n",
    "        high=stock['High'],\n",
    "        low=stock['Low'],\n",
    "        close=stock['Close']\n",
    "    ))\n",
    "\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6d8d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(ticker):\n",
    "    stock=pd.read_csv(f'C:\\\\Users\\\\mahdi\\\\Desktop\\\\stock data\\\\Data2023_1D\\\\{ticker}.csv')\n",
    "    stock.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "    return stock\n",
    "\n",
    "\n",
    "def cluster_zones(zones,candle_volume):\n",
    "    new_zones=[]\n",
    "    i=0\n",
    "    while i<len(zones)-1:\n",
    "        j=i+1\n",
    "        new_zone=0\n",
    "        while j<len(zones) and abs((zones[i]-zones[j]))/candle_volume<=1.5:\n",
    "            new_zone=(zones[i]+zones[j])/2\n",
    "            j+=1\n",
    "        if new_zone>0:\n",
    "            new_zones.append(round(new_zone,2))\n",
    "        else:\n",
    "            new_zones.append(zones[i])\n",
    "        i=j\n",
    "    return new_zones\n",
    "def get_zones(stock):\n",
    "    zones=[]\n",
    "    for i in range(1,len(stock)-2):\n",
    "        bullish0=stock['Close'].iloc[i-1]>stock['Open'].iloc[i-1]\n",
    "        bullish1=stock['Close'].iloc[i]>stock['Open'].iloc[i]\n",
    "        bullish2=stock['Close'].iloc[i+1]>stock['Open'].iloc[i+1]\n",
    "        if bullish0 and bullish1 and bullish2==False:\n",
    "            zones.append(stock['High'].iloc[i])\n",
    "        if bullish0==False and bullish1 and bullish2:\n",
    "            zones.append(stock['Low'].iloc[i])\n",
    "    zones=np.sort(zones)\n",
    "    return zones\n",
    "\n",
    "def candle_construction(df,candle_volume,zones):\n",
    "    df.loc[:, \"price_progress\"] = (df['Close'] - df['Close'].shift(1)) / candle_volume\n",
    "    diff_zones=[(df['Close'].iloc[len(df)-1]-zones[i])/candle_volume for i in range(len(zones))]\n",
    "    df=df[['price_progress']]\n",
    "    diff_zones=np.sort(diff_zones)\n",
    "    neg_diffzone=-1000\n",
    "    pos_diffzone=1000\n",
    "    for i in range(len(diff_zones)):\n",
    "        if diff_zones[i]<0:\n",
    "            neg_diffzone=diff_zones[i]\n",
    "        else:\n",
    "            pos_diffzone=diff_zones[i]\n",
    "            break\n",
    "    if abs(neg_diffzone)<pos_diffzone:\n",
    "        diff_zones=neg_diffzone\n",
    "    else:\n",
    "        diff_zones=pos_diffzone\n",
    "#     x=df[1:len(df)-1].values\n",
    "    return (df[1:],diff_zones)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_file_name_if_size_greater_than(file_path, size_threshold_kb):\n",
    "    try:\n",
    "        # Get the size of the file in bytes\n",
    "        size_in_bytes = os.path.getsize(file_path)\n",
    "\n",
    "        # Convert the size to kilobytes\n",
    "        size_in_kb = size_in_bytes / 1024.0\n",
    "\n",
    "        # Check if the file size is greater than the threshold\n",
    "        if size_in_kb > size_threshold_kb:\n",
    "            file_name_without_extension = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            return file_name_without_extension\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return None    \n",
    "    \n",
    "    \n",
    "def generate_planes(dim=10):\n",
    "    first_plan=np.random.random(dim)\n",
    "    second_plan=np.random.random(dim)\n",
    "    third_plan=np.random.random(dim)\n",
    "    return first_plan,second_plan,third_plan\n",
    "\n",
    "first_plane0,second_plane0,third_plane0=generate_planes()\n",
    "first_plane1,second_plane1,third_plane1=generate_planes()\n",
    "first_plane2,second_plane2,third_plane2=generate_planes()\n",
    "\n",
    "def get_hashcode(x,first_plane,second_plane,third_plane):\n",
    "    hash_code=[0,0,0]\n",
    "    if np.dot(x,first_plane)>=0:\n",
    "        hash_code[0]=1\n",
    "    if np.dot(x,second_plane)>=0:\n",
    "        hash_code[1]=1\n",
    "    if np.dot(x,third_plane)>=0:\n",
    "        hash_code[2]=1\n",
    "    return hash_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C:\\\\Users\\\\mahdi\\\\Desktop\\\\stock data\\\\Data2023_1D\\\\'\n",
    "xlsx_files = glob.glob(folder_path + '*.csv')\n",
    "tickers=[]\n",
    "index_to_delete=[]\n",
    "lookback=10\n",
    "for file in xlsx_files:\n",
    "    size_threshold_kb = 0\n",
    "    tickers.append(get_file_name_if_size_greater_than(file, size_threshold_kb))\n",
    "for ticker in tickers:\n",
    "    print(ticker)\n",
    "    stock=get_stock_data(ticker)\n",
    "    zones=get_zones(stock)\n",
    "    final_data=pd.DataFrame(columns=([f'pp_{j}' for j in range(1,lookback+1)]))\n",
    "    for i in range(0,len(stock)):\n",
    "        df=stock[i:i+lookback]\n",
    "        candle_volume=(stock['High']-stock['Low']).median()\n",
    "        zones1=cluster_zones(zones.copy(),candle_volume)\n",
    "        df,diff_zones=candle_construction(df.copy(),candle_volume,zones1)\n",
    "#         df.to_csv('')\n",
    "        x=np.append(df.values,diff_zones)\n",
    "        if x.shape[0]==lookback:\n",
    "            hash_code0=get_hashcode(x,first_plane0,second_plane0,third_plane0)\n",
    "            hash_code1=get_hashcode(x,first_plane1,second_plane1,third_plane1)\n",
    "            hash_code2=get_hashcode(x,first_plane2,second_plane2,third_plane2)\n",
    "            x=x.reshape(1,-1)\n",
    "            df=pd.DataFrame(x,columns=([f'pp_{j}' for j in range(1,lookback+1)]))\n",
    "            df['start_date']=stock['Datetime'].iloc[i]\n",
    "            df['hash0_0']=hash_code0[0]\n",
    "            df['hash0_1']=hash_code0[1]\n",
    "            df['hash0_2']=hash_code0[2]\n",
    "            \n",
    "            df['hash1_0']=hash_code1[0]\n",
    "            df['hash1_1']=hash_code1[1]\n",
    "            df['hash1_2']=hash_code1[2]\n",
    "            df['hash2_0']=hash_code2[0]\n",
    "            df['hash2_1']=hash_code2[1]\n",
    "            df['hash2_2']=hash_code2[2]\n",
    "            final_data=pd.concat([final_data,df])\n",
    "\n",
    "    final_data['ticker']=ticker\n",
    "    final_data.to_csv(f'C:\\\\Users\\\\mahdi\\\\Desktop\\\\workshops\\\\Python workshop\\\\tradeProject\\\\models\\\\SameHistory detection\\\\data\\\\{ticker}.csv',index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a593cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('first_plane0.npy', first_plane0)\n",
    "np.save('second_plane0.npy', second_plane0)\n",
    "np.save('third_plane0.npy', third_plane0)\n",
    "\n",
    "np.save('first_plane1.npy', first_plane1)\n",
    "np.save('second_plane1.npy', second_plane1)\n",
    "np.save('third_plane1.npy', third_plane1)\n",
    "\n",
    "np.save('first_plane2.npy', first_plane2)\n",
    "np.save('second_plane2.npy', second_plane2)\n",
    "np.save('third_plane2.npy', third_plane2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
